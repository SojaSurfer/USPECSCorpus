{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7caa4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ae9429",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1344\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1344\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1336\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1382\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1477\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1475\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1319\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     ssl\u001b[38;5;241m.\u001b[39m_create_default_https_context \u001b[38;5;241m=\u001b[39m _create_unverified_https_context\n\u001b[0;32m---> 28\u001b[0m newsgroups_all \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(newsgroups_all\u001b[38;5;241m.\u001b[39mdata))\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(sset, cats)\u001b[0m\n\u001b[1;32m      4\u001b[0m     newsgroups_dset \u001b[38;5;241m=\u001b[39m fetch_20newsgroups(subset\u001b[38;5;241m=\u001b[39msset,\n\u001b[1;32m      5\u001b[0m                                         remove\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfooters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m                                         shuffel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m----> 8\u001b[0m     newsgroups_dset \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_20newsgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mremove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheaders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfooters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquotes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newsgroups_dset\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/datasets/_twenty_newsgroups.py:320\u001b[0m, in \u001b[0;36mfetch_20newsgroups\u001b[0;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y, n_retries, delay)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_if_missing:\n\u001b[1;32m    319\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading 20news dataset. This may take a few minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 320\u001b[0m     cache \u001b[38;5;241m=\u001b[39m \u001b[43m_download_20newsgroups\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtwenty_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20Newsgroups dataset not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/datasets/_twenty_newsgroups.py:79\u001b[0m, in \u001b[0;36m_download_20newsgroups\u001b[0;34m(target_dir, cache_path, n_retries, delay)\u001b[0m\n\u001b[1;32m     76\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(target_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading dataset from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (14 MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m, ARCHIVE\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m---> 79\u001b[0m archive_path \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_remote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mARCHIVE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecompressing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, archive_path)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(archive_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/datasets/_base.py:1466\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname, n_retries, delay)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1466\u001b[0m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    241\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    533\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1347\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1345\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>"
     ]
    }
   ],
   "source": [
    "# laod 20 newsgroups data\n",
    "def load_dataset(sset, cats):\n",
    "    if cats==[]:\n",
    "        newsgroups_dset = fetch_20newsgroups(subset=sset,\n",
    "                                            remove=('headers', 'footers', 'quotes'),\n",
    "                                            shuffel=True)\n",
    "    else: \n",
    "        newsgroups_dset = fetch_20newsgroups(subset = sset,\n",
    "                                             categories=cats,\n",
    "                                             remove=('headers', 'footers', 'quotes'),\n",
    "                                             shuffle=True)\n",
    "    return newsgroups_dset\n",
    "\n",
    "categories = [\"comp.windows.x\", \"misc.forsale\", \"rec.autos\"]\n",
    "categories += [\"rec.motorcycles\", \"rec.sport.baseball\", \"rec.sport.hockey\"]\n",
    "categories += [\"sci.crypt\", \"sci.med\", \"sci.space\"]\n",
    "categories += [\"talk.politics.mideast\"]\n",
    "\n",
    "\n",
    "newsgroups_all = load_dataset('all', categories)\n",
    "\n",
    "print(len(newsgroups_all.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fca20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - import libraries\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import SnowballStemmer\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a48192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - define preprocessing function\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stem(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text, min_len=4):\n",
    "        if token not in stopwords:\n",
    "            result.append(stem(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706b0ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newsgroups_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# preprocess - inspect results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m doc_sample \u001b[38;5;241m=\u001b[39m \u001b[43mnewsgroups_all\u001b[49m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal document: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc_sample)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newsgroups_all' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess - inspect results\n",
    "doc_sample = newsgroups_all.data[0]\n",
    "print('Original document: ')\n",
    "print(doc_sample)\n",
    "\n",
    "print('\\n\\nTokenized document: ')\n",
    "words = []\n",
    "for token in gensim.utils.tokenize(doc_sample):\n",
    "    words.append(token)\n",
    "print(words)\n",
    "\n",
    "print('\\n\\nPreprocessed document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d239f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\txpert, cursor, keyboard, cursor, key, mous, avail, hint, welcom, thank\n",
      "1\tobtain, copi, open, look, widget, obtain, need, order, copi, thank\n",
      "2\tright, signal, strong, live, west, philadelphia, perfect, sport, fan, dream\n",
      "3\tcanadian, thing, coach, boston, bruin, colorado, rocki, summari, post, gather\n",
      "4\theck, feel, like, time, includ, cafeteria, work, half, time, headach\n",
      "5\tdamn, right, late, climb, meet, morn, bother, right, foot, asleep\n",
      "6\tolympus, stylus, pocket, camera, smallest, class, includ, time, date, stamp\n",
      "7\tinclud, follow, chmos, clock, generat, driver, processor, chmos, eras, prom\n",
      "8\tchang, intel, discov, xclient, xload, longer, work, bomb, messag, error\n",
      "9\ttermin, like, power, server, run, window, manag, special, client, program\n"
     ]
    }
   ],
   "source": [
    "# preprocess - inspect output of group of documents\n",
    "for i in range(0, 10):\n",
    "    print(str(i) + '\\t' + \", \".join(preprocess(newsgroups_all.data[i])[:10])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707b8e8d-7c0f-4046-8866-032894c75d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #damit kann man sich den Fortschritt des Loops anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3201161-638b-41d8-b332-554c26b1c431",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# preprocess - process all documents\u001b[39;00m\n\u001b[0;32m      2\u001b[0m processed_docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(newsgroups_all\u001b[38;5;241m.\u001b[39mdata))):\n\u001b[0;32m      4\u001b[0m     processed_docs\u001b[38;5;241m.\u001b[39mappend(preprocess(newsgroups_all\u001b[38;5;241m.\u001b[39mdata[i]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(processed_docs))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess - process all documents\n",
    "processed_docs = []\n",
    "for i in tqdm(range(0, len(newsgroups_all.data))):\n",
    "    processed_docs.append(preprocess(newsgroups_all.data[i]))\n",
    "    \n",
    "print(len(processed_docs))\n",
    "\n",
    "print(processed_docs[0:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a29fa5-9590-4945-85b8-fa71097be885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39350\n",
      "0 avail\n",
      "1 cursor\n",
      "2 hint\n",
      "3 key\n",
      "4 keyboard\n",
      "5 mous\n",
      "6 thank\n",
      "7 welcom\n",
      "8 xpert\n",
      "9 copi\n"
     ]
    }
   ],
   "source": [
    "# preprocess - convert word content into dictionary\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "print(len(dictionary))\n",
    "\n",
    "index = 0\n",
    "for key, value in dictionary.iteritems():\n",
    "    print(key, value)\n",
    "    index +=1\n",
    "    if index > 9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38375969-b9d0-4e7c-8072-afc2b47aef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9850/9850 [00:00<00:00, 24855.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess - further dimensionality reduction\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n = 10000)\n",
    "print(len(dictionary))\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in tqdm(processed_docs)]\n",
    "print(bow_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45eba197-3a87-4ce2-9603-0e08a028112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 6316.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 0 = \"avail\": occurrences=1\n",
      "Key 1 = \"cursor\": occurrences=2\n",
      "Key 2 = \"hint\": occurrences=1\n",
      "Key 3 = \"key\": occurrences=1\n",
      "Key 4 = \"keyboard\": occurrences=1\n",
      "Key 5 = \"mous\": occurrences=1\n",
      "Key 6 = \"thank\": occurrences=1\n",
      "Key 7 = \"welcom\": occurrences=1\n",
      "Key 8 = \"xpert\": occurrences=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess - check word stems behind IDs from dictionary\n",
    "\n",
    "bow_doc = bow_corpus[0]\n",
    "\n",
    "for i in tqdm(range(len(bow_doc))):\n",
    "    print(f\"Key {bow_doc[i][0]} = \\\"{dictionary[bow_doc[i][0]]}\\\": occurrences={bow_doc[i][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462be2e2-becd-42b0-a262-303480458536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run LDA\n",
    "id2word = dictionary\n",
    "corpus = bow_corpus\n",
    "# jetzt werden Hyperparameter gesetzt\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=10,\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                chunksize=1000,\n",
    "                                                passes=10,\n",
    "                                                alpha='symmetric',\n",
    "                                                iterations=100,\n",
    "                                                per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678719b9-6fdf-4d8f-9cb7-5475928da432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:40<02:01, 40.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9872220135095524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:20<01:20, 40.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.116066325049365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [02:03<00:41, 41.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4870672483583807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:13<00:00, 48.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.9346177059722134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "id2word = dictionary\n",
    "corpus = bow_corpus\n",
    "\n",
    "topics = [5, 10, 20, 40]\n",
    "\n",
    "for i in tqdm(topics): \n",
    "\n",
    "    lda_model_i = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=i,\n",
    "                                                    random_state=100,\n",
    "                                                    update_every=1,\n",
    "                                                    chunksize=1000,\n",
    "                                                    passes=10, #Anzahl der Durchgänge, 10 ist recht wenig, kann mehr\n",
    "                                                    alpha='symmetric',#wie sich Wörter über die Themen verteilen (geht auch asymetric und auto), aber symetric ist neutraler\n",
    "                                                    iterations=100,#Anzahl der Durchläufe\n",
    "                                                    per_word_topics=True)\n",
    "    u_mass_i = CoherenceModel(model=lda_model_i, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "    \n",
    "    print(u_mass_i.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21723519-1098-4b35-8d77-c6c02c24d1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.116066325049365\n",
      "0.6309025191282835\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "u_mass = CoherenceModel(model=lda_model, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "c_v = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "print(u_mass.get_coherence())\n",
    "print(c_v.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "412483b8-23b0-4b7d-9c99-83d9ca2c50a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.021*\"encrypt\" + 0.018*\"secur\" + 0.018*\"chip\" + 0.016*\"govern\" + 0.013*\"clipper\" + 0.012*\"public\" + 0.010*\"privaci\" + 0.010*\"key\" + 0.010*\"phone\" + 0.009*\"algorithm\"\n",
      "Topic: 1 \n",
      "Words: 0.017*\"appear\" + 0.014*\"copi\" + 0.013*\"cover\" + 0.013*\"star\" + 0.013*\"book\" + 0.011*\"penalti\" + 0.010*\"black\" + 0.009*\"comic\" + 0.008*\"blue\" + 0.008*\"green\"\n",
      "Topic: 2 \n",
      "Words: 0.031*\"window\" + 0.015*\"server\" + 0.012*\"program\" + 0.012*\"file\" + 0.012*\"applic\" + 0.012*\"display\" + 0.011*\"widget\" + 0.010*\"version\" + 0.010*\"motif\" + 0.010*\"support\"\n",
      "Topic: 3 \n",
      "Words: 0.015*\"space\" + 0.007*\"launch\" + 0.007*\"year\" + 0.007*\"medic\" + 0.006*\"patient\" + 0.006*\"orbit\" + 0.006*\"research\" + 0.006*\"diseas\" + 0.005*\"develop\" + 0.005*\"nasa\"\n",
      "Topic: 4 \n",
      "Words: 0.018*\"armenian\" + 0.011*\"peopl\" + 0.008*\"kill\" + 0.008*\"said\" + 0.007*\"turkish\" + 0.006*\"muslim\" + 0.006*\"jew\" + 0.006*\"govern\" + 0.005*\"state\" + 0.005*\"greek\"\n",
      "Topic: 5 \n",
      "Words: 0.024*\"price\" + 0.021*\"sale\" + 0.020*\"offer\" + 0.017*\"drive\" + 0.017*\"sell\" + 0.016*\"includ\" + 0.013*\"ship\" + 0.013*\"interest\" + 0.011*\"ask\" + 0.010*\"condit\"\n",
      "Topic: 6 \n",
      "Words: 0.018*\"mail\" + 0.016*\"list\" + 0.015*\"file\" + 0.015*\"inform\" + 0.013*\"send\" + 0.012*\"post\" + 0.012*\"avail\" + 0.010*\"request\" + 0.010*\"program\" + 0.009*\"includ\"\n",
      "Topic: 7 \n",
      "Words: 0.019*\"like\" + 0.016*\"know\" + 0.011*\"time\" + 0.011*\"look\" + 0.010*\"think\" + 0.008*\"want\" + 0.008*\"thing\" + 0.008*\"good\" + 0.007*\"go\" + 0.007*\"bike\"\n",
      "Topic: 8 \n",
      "Words: 0.033*\"game\" + 0.022*\"team\" + 0.017*\"play\" + 0.015*\"year\" + 0.013*\"player\" + 0.011*\"season\" + 0.008*\"hockey\" + 0.008*\"score\" + 0.007*\"leagu\" + 0.007*\"goal\"\n",
      "Topic: 9 \n",
      "Words: 0.013*\"peopl\" + 0.012*\"think\" + 0.011*\"like\" + 0.009*\"time\" + 0.009*\"right\" + 0.009*\"israel\" + 0.009*\"know\" + 0.006*\"reason\" + 0.006*\"point\" + 0.006*\"thing\"\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {index} \\nWords: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1c9593-39f4-41dd-9653-ea4a49627298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze topics - main topics for each document in the collection\n",
    "def analyse_topics(ldamodel, corpus, text):\n",
    "    main_topic = {}\n",
    "    percentage = {}\n",
    "    keywords = {}\n",
    "    text_snippets = {}\n",
    "    \n",
    "    for i, topic_list in enumerate(ldamodel [corpus]):\n",
    "        topic = topic_list[0]\n",
    "        topic = sorted(topic, key = lambda x: (x[1]), reverse = True)\n",
    "        \n",
    "        for j, (topic_num, prop_topic) in enumerate(topic):\n",
    "            if j == 0:\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp[:5]])\n",
    "                main_topic[i] = int(topic_num)\n",
    "                percentage[i] = round(prop_topic, 4)\n",
    "                keywords[i] = topic_keywords\n",
    "                text_snippets[i] = text[i][:8]\n",
    "            else:\n",
    "                break\n",
    "    return main_topic, percentage, keywords, text_snippets\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13007ddd-0650-453b-9f6c-7aec8ac28181",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topic, percentage, keywords, text_snippets = analyse_topics(lda_model, bow_corpus, processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f721c0-fbac-4aa3-ac89-6a31eac53bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Main Topic Contribution (%) Keywords                               Snippet                                                                           \n",
      "0  2          0.8268           window, server, program, file, applic\n",
      " ['xpert', 'cursor', 'keyboard', 'cursor', 'key', 'mous', 'avail', 'hint']         \n",
      "1  6          0.4741           mail, list, file, inform, send\n",
      "        ['obtain', 'copi', 'open', 'look', 'widget', 'obtain', 'need', 'order']           \n",
      "2  7          0.4230           like, know, time, look, think\n",
      "         ['right', 'signal', 'strong', 'live', 'west', 'philadelphia', 'perfect', 'sport'] \n",
      "3  8          0.4159           game, team, play, year, player\n",
      "        ['canadian', 'thing', 'coach', 'boston', 'bruin', 'colorado', 'rocki', 'summari'] \n",
      "4  9          0.9039           peopl, think, like, time, right\n",
      "       ['heck', 'feel', 'like', 'time', 'includ', 'cafeteria', 'work', 'half']           \n",
      "5  7          0.6291           like, know, time, look, think\n",
      "         ['damn', 'right', 'late', 'climb', 'meet', 'morn', 'bother', 'right']             \n",
      "6  3          0.3485           space, launch, year, medic, patient\n",
      "   ['olympus', 'stylus', 'pocket', 'camera', 'smallest', 'class', 'includ', 'time']  \n",
      "7  5          0.3799           price, sale, offer, drive, sell\n",
      "       ['includ', 'follow', 'chmos', 'clock', 'generat', 'driver', 'processor', 'chmos'] \n",
      "8  2          0.7943           window, server, program, file, applic\n",
      " ['chang', 'intel', 'discov', 'xclient', 'xload', 'longer', 'work', 'bomb']        \n",
      "9  2          0.6383           window, server, program, file, applic\n",
      " ['termin', 'like', 'power', 'server', 'run', 'window', 'manag', 'special']        \n"
     ]
    }
   ],
   "source": [
    "# analyze topics - print out main topic for each document in the collection\n",
    "\n",
    "indexes = []\n",
    "rows = []\n",
    "for i in range(0, 10):\n",
    "    indexes.append(i)\n",
    "rows.append(['ID', 'Main Topic', 'Contribution (%)', 'Keywords', 'Snippet' ])\n",
    "\n",
    "for idx in indexes:\n",
    "    rows.append([str(idx), f\"{main_topic.get(idx)}\",\n",
    "                f\"{percentage.get(idx):.4f}\",\n",
    "                f\"{keywords.get(idx)}\\n\",\n",
    "                f\"{text_snippets.get(idx)}\"])\n",
    "columns = zip(*rows)\n",
    "column_width = [max(len(item) for item in col) for col in columns]\n",
    "for row in rows:\n",
    "    print(''.join('{:{width}} '.format(row[i], width=column_width[i]) for i in range(0, len(row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08716335-d91d-40cc-87f5-c032806f3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "# analyze topics - visualize with pyLDAvis\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "#pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "#vis\n",
    "\n",
    "pyLDAvis.save_html(vis, 'lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238019ee-242b-4416-9bcb-1f24cdc4d92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
